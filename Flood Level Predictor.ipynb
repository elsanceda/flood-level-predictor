{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metro Manila Flood Level Predictor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a course requirement for the CS180 Artificial Intelligence Course of the Department of Computer Science, College of Engineering, University of the Philippines, Diliman under the guidance of Carlo Raquel for AY 2022-2023.\n",
    "\n",
    "This is a Multilayer Perceptron model trained to predict the flood level in Metro Manila given the latitude, longitude, elevation, and precipitation rate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset that will be used is the [Metro Manila Flood Landscape Data](https://www.kaggle.com/datasets/giologicx/aegisdataset) uploaded by GiologicX on Kaggle. It has five features: the location separated into the latitude and longitude coordinates, the flood height, the elevation in meters, and the precipitation rate in millimeters per hour. As explained by the dataset creator, the data was extracted from different sources. The flood data was taken from flood reports by Project NOAH, the location and elevation data was retrieved from NAMRIA, and the precipitation data was averaged from data from PAGASA. The creator specified using Spatial Kriging to acquire the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>flood_heig</th>\n",
       "      <th>elevation</th>\n",
       "      <th>precipitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.640394</td>\n",
       "      <td>121.055708</td>\n",
       "      <td>0</td>\n",
       "      <td>54.553295</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.698299</td>\n",
       "      <td>121.002132</td>\n",
       "      <td>0</td>\n",
       "      <td>21.856272</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.698858</td>\n",
       "      <td>121.100261</td>\n",
       "      <td>0</td>\n",
       "      <td>69.322807</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.571310</td>\n",
       "      <td>120.983334</td>\n",
       "      <td>0</td>\n",
       "      <td>10.987241</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.762232</td>\n",
       "      <td>121.075735</td>\n",
       "      <td>0</td>\n",
       "      <td>87.889847</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat         lon  flood_heig  elevation  precipitat\n",
       "0  14.640394  121.055708           0  54.553295           9\n",
       "1  14.698299  121.002132           0  21.856272          10\n",
       "2  14.698858  121.100261           0  69.322807          16\n",
       "3  14.571310  120.983334           0  10.987241           8\n",
       "4  14.762232  121.075735           0  87.889847          18"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_csv('AEGISDataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset for training and testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier requires a training set and a test set. Since the model will be predicting the flood height, then for each set, the column containing the flood height must be separated from the actual data. This also prevents the flood height from being affected by normalization.\n",
    "\n",
    "70% of the dataset will be used for training while the remianing 30% will be used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop('flood_heig', axis=1)\n",
    "y = data['flood_heig']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y,train_size=0.7, random_state=550)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Multilayer Perceptron model to work optimally, the data is normalized into the [-1,1] range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method that will be used for the model is Multilayer Perceptron, specifically, Multilayer Perceptron for Regression. According to a study by Mosavi et al. (2018), Multilayer Perceptron is one of the best and most popular machine learning methods for flood prediction. This method was chosen due to its simplicity, better ease of use, faster speed, and higher accuracy compared to other methods (Mosavi et al., 2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(3),max_iter=1000)\n",
    "mlp.fit(X_train,y_train)\n",
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate our Multilayer Perceptron Regression model using the Root Mean Squared Error (RMSE) and the R Squared (R2). The lower the RMSE and the higher the R2 score, the better the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.8027587894639463\n",
      "R2: 0.04370311992156306\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>5</td>\n",
       "      <td>2.697219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>3</td>\n",
       "      <td>2.331378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>2</td>\n",
       "      <td>2.120142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0</td>\n",
       "      <td>1.775570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0</td>\n",
       "      <td>2.142232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>0</td>\n",
       "      <td>2.254512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>3</td>\n",
       "      <td>2.011554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>4</td>\n",
       "      <td>2.266195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>2</td>\n",
       "      <td>2.758273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>3</td>\n",
       "      <td>2.785336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1053 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual  Predicted\n",
       "3127       5   2.697219\n",
       "2454       3   2.331378\n",
       "1710       2   2.120142\n",
       "214        0   1.775570\n",
       "704        0   2.142232\n",
       "...      ...        ...\n",
       "735        0   2.254512\n",
       "2400       3   2.011554\n",
       "3005       4   2.266195\n",
       "1202       2   2.758273\n",
       "2096       3   2.785336\n",
       "\n",
       "[1053 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"RMSE:\",np.sqrt(mean_squared_error(y_test,predictions)))\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test,predictions)\n",
    "print(\"R2:\",r2)\n",
    "\n",
    "comparison_df = pd.DataFrame({\"Actual\":y_test,\"Predicted\":predictions})\n",
    "comparison_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering that the output of the model ranges from 0-8, 1.8 is a decently high RMSE, and 0.04 is quite a low R2 score. Thus, the model is not very good at predicting flood height."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can be improved through hyperparameter tuning with GridSearchCV. Initial runs were done to determine the best solver, alpha, and activation values to use for the model. The run seen below is for determining the optimal values for the hidden layer sizes and initial learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(3, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(3, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(3, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(3, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(3, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(3, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(3, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(3, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   4.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(3, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(3, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ieiaiel Sanceda\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(3, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   6.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(3, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(3, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(3, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(3, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(4, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(4, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(4, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(4, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(4, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(4, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(4, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(4, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(4, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(4, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ieiaiel Sanceda\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(4, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ieiaiel Sanceda\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(4, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   7.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(4, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(4, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ieiaiel Sanceda\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(4, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   7.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(5, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(5, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(5, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(5, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(5, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(5, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(5, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(5, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   6.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(5, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(5, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(5, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ieiaiel Sanceda\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(5, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ieiaiel Sanceda\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(5, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   4.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(5, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   4.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(5, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(6, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(6, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(6, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(6, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(6, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(6, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(6, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(6, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(6, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(6, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ieiaiel Sanceda\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(6, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   5.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(6, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(6, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ieiaiel Sanceda\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(6, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ieiaiel Sanceda\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(6, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   6.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(7, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(7, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(7, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(7, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(7, 2), learning_rate_init=0.1, max_iter=1000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(7, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(7, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(7, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(7, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(7, 2), learning_rate_init=0.01, max_iter=1000, solver=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(7, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ieiaiel Sanceda\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(7, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=  11.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ieiaiel Sanceda\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(7, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ieiaiel Sanceda\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(7, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ieiaiel Sanceda\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(7, 2), learning_rate_init=0.001, max_iter=1000, solver=adam; total time=   4.5s\n",
      "{'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (5, 2), 'learning_rate_init': 0.01, 'max_iter': 1000, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'hidden_layer_sizes': [(3,2),(4,2),(5,2),(6,2),(7,2)], \n",
    "              'solver': ['adam'],\n",
    "              'alpha': [0.001],\n",
    "              'learning_rate_init': [0.1,0.01,0.001],\n",
    "              'max_iter': [1000], \n",
    "              'activation': ['tanh']} \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(MLPRegressor(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparametrized model results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once hyperparameter tuning is complete, we can evaluate the model using the same metrics used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.7092277583686766\n",
      "R2: 0.14035850632485547\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>5</td>\n",
       "      <td>2.144595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>3</td>\n",
       "      <td>2.209193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>2</td>\n",
       "      <td>1.683344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0</td>\n",
       "      <td>1.105277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0</td>\n",
       "      <td>1.563703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>0</td>\n",
       "      <td>2.397892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>3</td>\n",
       "      <td>1.133870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>4</td>\n",
       "      <td>2.797599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>2</td>\n",
       "      <td>3.384344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>3</td>\n",
       "      <td>2.425715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1053 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual  Predicted\n",
       "3127       5   2.144595\n",
       "2454       3   2.209193\n",
       "1710       2   1.683344\n",
       "214        0   1.105277\n",
       "704        0   1.563703\n",
       "...      ...        ...\n",
       "735        0   2.397892\n",
       "2400       3   1.133870\n",
       "3005       4   2.797599\n",
       "1202       2   3.384344\n",
       "2096       3   2.425715\n",
       "\n",
       "[1053 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_predictions = grid.predict(X_test)\n",
    "\n",
    "print(\"RMSE:\",np.sqrt(mean_squared_error(y_test,grid_predictions)))\n",
    "\n",
    "r2 = r2_score(y_test,grid_predictions)\n",
    "print(\"R2:\",r2)\n",
    "\n",
    "comparison_df = pd.DataFrame({\"Actual\":y_test,\"Predicted\":grid_predictions})\n",
    "comparison_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this new model yielded a lower RMSE and a higher R2 score compared to the untuned model. However, while the new model is better than the initial model, the scores are still unsatisfactory."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with existing models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An existing notebook comparing a linear regression model and a geospatial weighted regression model can be found [here](https://www.kaggle.com/code/giologicx/geospatial-weighted-regression). The linear regression model yielded an adjusted R2 score of 0.005312, which is lower than our tuned MLP model. However, the geospatial weighted regression model resulted in a score of 0.2934473, which is better than the tuned MLP model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the metrics used above, we can conclude that our model does not perform satisfactorily for the given dataset. The model with tuned hyperparameters yielded better results than the untuned model and the linear regression model in the existing notebook. However, the tuned model did not yield better results than the geospatial weighted regression model. The complex structure of geographical land, and the nature of flood height to vary greatly throughout a small interval of coordinates, might have been beyond what an MLP Regressor model could analyze. These shortcomings amight also be why the geospatial weighted regression model was created. Although previous studies have shown that MLP is one of the best models to use for flood prediction, the model is unoptimal for the chosen dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
